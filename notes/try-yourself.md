
Create PySpark notebook in jupyter,

load sector data from hdfs

write to spark, use different table name sectors_python 

it will create a table called sectors_python 

read from sectors_python using jdbc 

select * from sectors_python

--


create a database moviedb;
// table popular_movies shall be created using dataframe 

give permission to team user in mysql 

Refer S053 Movie Lens 

read hdfs movies, ratings, perform all tasks 

popularMoviesDf where we write csv, parquet etc 
instead of writing popularMoviesDf to hdfc, 

now write to moviedb.popular_movies

select * from  popular_movies in mysql 

--
create a dataframe from mysql moviedb.popular_movies... 
display the data in show 